{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ[\"PYTHONPATH\"])  # Should contain parent dirrectory of image_captioning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import editdistance\n",
    "import matplotlib.pyplot  as plt\n",
    "from matplotlib.pyplot import figure, imshow, axis\n",
    "from matplotlib.image import imread\n",
    "\n",
    "import torch\n",
    "\n",
    "import image_captioning.constants as C\n",
    "from image_captioning.caption import caption_image_beam_search, visualize_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.read_csv(str(C.SVHN_EVAL_PATH), dtype=np.object)\n",
    "report[\"score\"] = report[\"score\"].astype(np.float)\n",
    "report[\"probability\"]= np.exp(report[\"score\"])\n",
    "report[\"predicted\"] = report[\"predicted\"].fillna(\"\")\n",
    "report[\"edit_distance\"] = report.apply(lambda x: editdistance.eval(x[\"predicted\"], x[\"correct\"]), axis=1)\n",
    "report[\"norm_edit_distance\"] = report.apply(lambda x: x[\"edit_distance\"] / len(x[\"correct\"]), axis=1)\n",
    "report[\"delusion\"] = report[\"edit_distance\"] * report[\"probability\"] \n",
    "report[\"error\"] = report[\"predicted\"] != report[\"correct\"]\n",
    "report = report.sort_values(by=\"delusion\", ascending=False)\n",
    "report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report[[\"error\", \"norm_edit_distance\", \"edit_distance\"]].mean().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW = 30\n",
    "class args:\n",
    "    model = \"BEST_checkpoint_svhn_1_cap_per_img_5_min_word_freq.pth.tar\"\n",
    "    word_map = str(C.DIGIT_WORD_MAP_PATH)\n",
    "    beam_size = 3\n",
    "    smooth = True\n",
    "    \n",
    "device = \"cpu\"\n",
    "\n",
    "# Load model\n",
    "checkpoint = torch.load(args.model)\n",
    "decoder = checkpoint['decoder'].to(device)\n",
    "decoder.eval()\n",
    "encoder = checkpoint['encoder'].to(device)\n",
    "encoder.eval()\n",
    "\n",
    "# Load word map (word2ix)\n",
    "with open(args.word_map, 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "rev_word_map = {v: k for k, v in word_map.items()}  # ix2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, (index, row) in enumerate(report.iterrows()):\n",
    "    if i > SHOW:\n",
    "        break\n",
    "    # Encode, decode with attention and beam search\n",
    "    seq, alphas = caption_image_beam_search(encoder, decoder, row[\"path\"], word_map, args.beam_size)\n",
    "    alphas = torch.FloatTensor(alphas)\n",
    "    # Visualize caption and attention of best sequence\n",
    "    visualize_att(row[\"path\"], seq, alphas, rev_word_map, args.smooth)\n",
    "    plt.title(\"correct: %s, predicted: %s\\ndistance: %d, prob: %.3f\" % (\n",
    "        row[\"correct\"], row[\"predicted\"], row[\"edit_distance\"], row[\"probability\"]), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
